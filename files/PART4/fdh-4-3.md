---
title: 'Foundations in Digital Humanities 4.3'
subtitle: 'Bot Management'
author:
 - Frederic Kaplan

# Don't change the following lines
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyfoot[L]{-release-version-}
output: pdf_document

---

# Bot Management

## Theses

6 May 2011 : The First Flash Crash at Wall Street

1) When cultural systems are characterised by specific function to optimise, algorithms become a relevant alternative to human actions. 

2) When the number of actions decided by algorithms become signifiant compared to human actions, the shape of cultural system change profoundly. 

## Bots on Twitter

Examples : Pentametron, everyword, Professor Jocular, NSA Prism

Tay.ai

Twitter bot in politics

Mistakenly arguing with a bot

Detecting bots : Botometer

“We found that approximately 15% of the users active in the political conversation one month prior to the 2016 election were likely bots… and they were responsible to about one in five such political tweets (nearly 20%).”

Emilio Ferrara, Botometer

## Bots on Wikipedia

### Wikipedia was built by bots

Wikipedia is not only the work of community of users. It is also the work of hundred of bots that everyday shape and control written content. 

Bots and foreign language

Wifification of public domain content 

2002 : « Federal Standard 1037c », a technical dictionary is imported and wikified by an algorithm.

Articles from the  Easton's Bible Dictionary », a book from the 19e century are likewise imported to create non existant pages. 

This has resulted in the introduction of hundred of pages with a anachronic Victorian prose. 

### The logic of templates

« Ram-bot » produced the base articles for 30’000 American cities. 

In 2008,« Clue-bot II » created 15 000 small articles about asteroids using a Database from NASA. These articles were updated and translated. Unfortunately the database used was quite old and contained errors. It took a lot of time to clean the effect of this mass importation. 

Vandalism: ClueBot NG identifies and correct acts of vandalism like the insertion of insults non coherent with a given page.

Other bots

\- Detect copyright violation 

\- Link pages from different language version of Wikipedia

\- Automatically block pages that get updated a too high rate. 

\- Correct syntax errors

The bots ambivalence lies in their double nature being both a computational formalisation of a behaviour file and the agent who applies the rule

**Hagermanbot crisis** : Gendarme Vs “Gendarme couché”

## Content transforming Bots

#### Algorithm and language mediation

It started with autocompletion 

What does Google do with its auto-completion features

Natural language vs commercial language

Googlish vs English

Extension of the commercial domain of natural languages

The extension of the commercial domain of natural language is based on two principles 

(1) The regularisation of language by linguistic protheses 

(2) The multiplication of linguistic protheses 

Prothesis principle : Every prothesis can be used by bots instead of human users .

### Primary and secondary resources

(a) Primary resources produced only by humans (oral conversation, text from book scans)

(b) Secondary resources produced by bots based on Primary resources  (automatic translation, article produced by algorithms, some spams)

How can we distinguish primary from secondary resources ?

A risk of pollution of primary resources …

Google translate issues 

Drinking in polluted water. 

All this is true for images as the number ai-generated images outgrow the number of natural images

## Summary

The massive arrival of bot and bot-transformed content in cultural system may create next Flash Crash for culture. 

Language is changing incorporating the morphology of secondary resources. 

Visual code are changing incorporating the morphology of secondary resources. 

Culture in the 2050 may be quite different from what we have kwown since then. 





## Question and Answers 

## Further Reading
