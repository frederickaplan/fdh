---
title: 'Foundations in Digital Humanities 1.2'
subtitle: 'Digital Humanities as a Structured Research Field'
author:
 - Frederic Kaplan

# Don't change the following lines
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyfoot[L]{-release-version-}
output: pdf_document

---

# FDH-1-2: Digital Humanities as a Structured Research Field

#### Core theses explored in this chapter

- Digital Humanities can be defined as the field dealing with Big Cultural Datasets
- This approach permits to structure the research field, going from Big Cultural Data to Digital Culture, and, beyond, to Digital Experiences.

#### Contents:
> 1. Digital Humanities as field dynamically structured by tensions
>> 1.1. Overcoming the initial lack of a definition for Digital Humanities // 1.2. Tensions and debates shaping Digital Humanities // 1.3. Big Data DH vs. Small Data DH //
> 2. Digital Humanities deal with Big Cultural Datasets
> 3. Big Data and its two structuring narratives
>> 3.1. Data Deluge // 3.2. Big Science //
> 4. The four dimensions of Data Bigness
>> 4.1. Technological breaks // 4.2. Open-endedness // 4.3. Intrinsic Relations // 4.4. Paradigm Shifts //
> 5. A New Definition of Digital Humanities
>> 5.1. Big Cultural Datasets as a defining characteristic of Digital Humanities // 5.2. The two definitions of Digital Humanities //
> 6. The Three Circles Representation of Digital Humanities
>> 6.1. First Circle: Big Cultural Data // 6.2. Second Circle: Digital Culture // 6.3. Third Circle: Digital Experiences //
>7. Conclusion
>>7.1. Summary // 7.2. In the next chapter //

## 1. Digital Humanities as field dynamically structured by tensions

### 1.1. Overcoming the initial lack of a definition for Digital Humanities
Defining the nature and the boundaries of digital humanities is a long-discussed and unsolved issue, not only because there is no consensus on this question but also because digital humanities are currently undergoing a profound transformation that calls for a reconsideration of its fundamental concepts.

For years, digital humanities have been loosely regrouping computational approaches of humanities research problems and critical reflections on the effects of digital technologies on culture and knowledge. They emerged as a new label, rebranding and enlarging the idea of “humanities computing”.  Around this new name and under a “big tent,” a progressively larger community of practice thrived.

Each work at the intersection of Computer Science and the Humanities could potentially be part of this welcoming trend. Researchers gathered in national and international meetings, exchanged their views on blogs and mailing lists. If not a well-bounded field, digital humanities were surely a lively conversation.

The welcoming "digital humanities" label opened doors, connected separated academic silos, built bridges between information sciences and the various disciplines loosely forming what are called the humanities.

### 1.2. Tensions and debates shaping Digital Humanities
However, openness was always associated with a need for introspection, self-reflexive writings, tentative boundary definitions, the “What are digital humanities” articles and monographs became a genre of its own structured around several narratives of exclusion and inclusion. Digital humanities as a research domain define themselves dynamically in the negotiation of these tensions.

- **Humanists vs. Digital Humanists**: When does research in the humanities become digital humanities ? Is it enough for humanities scholar to have a website to become a digital humanist ? Does the use of a computer in humanities research make digital humanities research ?
- **Computer scientists vs. humanists in DH**: Should we still distinguish computer scientists and humanists in digital humanities communities ? Is C.P. Snow's “*_two cultures tension_*" between science and humanities still relevant ? Are digital humanities a form of “technical upgrade” of the humanities disciplines? Are digital humanities just a particular “application” of the Computer Science fields?
- **Makers vs. Interpreters**: Are digital humanities only about “building things” ? If you are not a “maker”, should you still be considered a “digital humanist” ? Is there room for purely interpretative digital humanities ?
- **Distant readers vs. Close readers**: Are Digital Humanities only about _"Distant Reading"_ ? To study literature, should we stop reading books and only focus on quantitative algorithmic measures ? Can digital humanities also enhance close reading experience ? Are “distant trading” approaches a form of radical digital humanities ?
- **Question-driven vs Data-driven research:** Should research in Digital Humanities start with a Question/Hypothesis and then look for data or should it start from Data, search for patterns and then questions/hyptheses.

These open-to-debate dichotomies show how much of breeding ground for questioning and ideas current Digital Humanities are. An additional tension should now be studied in greater detail, for it is a possible step toward a better definition of Digital Humanities.

### 1.3. Big Data DH vs. Small Data DH
Research in Big Data Digital Humanities focuses on large or dense cultural datasets, which call for new processing and interpretation methods. Big Data are “big” when, for instance, “manual” analysis becomes cumbersome and new study and interpretation methods must be invented.

It is important to note that the massiveness of Big Data is not tightly linked to a certain number of Terabytes, but instead with more subtle characteristics which we will shortly see.

In comparison, the Small Data Digital Humanities regroup more focused works that do not use massive data processing methods and explore other interdisciplinary dimensions linking computer science and humanities research. Small Data are small in the sense that it is not only smaller-scale but also well-bounded. By contrast, Big Data DH is characterised by the study of larger open-ended objects.

We will argue that Big Data research in digital humanities can be characterised by common methodologies and objects of studies, therefore transcending some of the tensions that have structured digital humanities so far.

## 2. Digital Humanities deal with Big Cultural Datasets

Massive cultural digital objects include large-scale corpus like the millions of books scanned by Google and the ones produced by numerous other digitization initiatives, the millions of photos and micro-messages shared on social network services, giant geographical information systems like Google Earth, or the ever expanding networks of academic papers citing one another. These interconnected objects – either digitally born or reconstructed through digitization pipelines – are too big to be read or watched. The traditional 1:1 ratio of a single scholar confronted with one document cannot cope with such abundance. Moreover, their boundaries are sometimes fuzzy, their content partially unknown and, likely to be in continuous expansion. These characteristics make them profoundly different from corpora traditionally studied by humanities researchers, despite surface resemblances.

The confrontation with these “massive” objects calls for fundamental questions. What can really be extracted from these huge datasets and what interpretations can be drawn based on these extractions? Will we learn more by analyzing 10 millions books that we cannot read individually or by reading five carefully? What is the role of algorithms for mining, shaping, and representing these large digital objects?

In order to understand the specificity of Big Cultural Dataset we should understand what Big Data are and what are the particularities of Cultural Datasets in this respect.

## 3. Big Data and its two structuring narratives

The term Big Data is associated with two foundational narratives, both of which present it as an epochal paradigm shift. In the **Data Deluge** narrative, Big Data is a reaction to an unexpected abundance of information. In the **Big Science** narrative, Big Data is a structured effort by the international scientific community to crack very hard problems by joining research forces and creating large-scale infrastructures. Both narratives contribute to structuring a multifaceted definition of the bigness of Big Data.

### 3.1. Data Deluge
In the data deluge narrative, Big Data is born out of the possibilities of the Internet and digital communication networks. In the last decade, several companies and research groups realized that the fluxes of real-time information that irrigate endlessly growing worldwide information systems have the potential to constitute an original knowledge base for understanding the present and anticipating the future.

From that perspective, Big Data research essentially tries to convert these fluxes into structured knowledge systems that document the lives of people, companies and institutions, aggregating information about places, topics, or events. The resulting knowledge systems are coded in machine-readable formats, facilitating data mining and exchanges. This general transformative process has been called **\*datafication\***. In such a perspective, Big Data research is the science behind massive datafication.

### 3.2. Big Science
Interest in Big Data has another —slightly older— origin that is connected to the constitution and management of very large scientific archives: what has been called Big Science. In this Big Data narrative, methodologies were initially pioneered in some domains of life sciences, climatology, astronomy, and physics. The _Human Genome Project_, starting with its creation in 1989 to its achieved target in 2001, paved the way for large-scale collaborative research infrastructures and experimented in publishing the resulting data sets and results. The massive data produced by CERN required the construction of new software and hardware systems. International attempts to model and simulate the brain based on massive curated experimental data revealed new challenges in the link between measures and simulation.

The Big Science narrative insists on tackling the challenge of organising collaborations on an international level despite academic competition, designing information pipelines to harness the massiveness of the data produced and on the relevant use of algorithmic simulation to test the coherence of the data and extrapolate in order to make new predictions.

## 4. The four dimensions of Data Bigness

### 4.1. Technological breaks
- **Technology**: _Big Data is big in the sense that it “hurts” to compute it using traditional “manual” methods._

Its bigness calls for new strategies of processing and interpretation. The “envisioned” data volume needs special storage and computing infrastructure to be managed. Such data-intensive computing infrastructures include, for instance, large clusters and parallelization algorithms. In turn, such technological progress opens the way for storing and computing even more data.

### 4.2. Open-endedness
- **Open-endedness**: _Big Data is big when it is in a state of continuous open-ended expansion._

Large-scale databases of book scans are in _perpetual expansion_, photos uploaded on social networks constitute ever-growing datasets, and the volume of micro-messages sent per day keeps rising.

This calls for iterative methodologies, different from the ones adapted to close datasets, and which are able to cope with the ever-evolving continuity of data fluxes. From the perspective of Big Data, every dataset tends to become a data stream (i.e., a part of the data deluge).

### 4.3. Intrinsic Relations
- **Relational**: _Big Data is big not only because of its size but because of its relationship with other data and its “fundamentally networked” nature._

The semantic web approach that hypothesizes the existence of a Giant Global Graph, a machine-readable version of the information contained on the World Wide Web, is a typical example of such kind of interlinked datasets.

### 4.4. Paradigm Shifts
- **Paradigmatic**: _Big Data is big when there is sufficient data to perform new forms of data-driven sciences._

It is currently being debated how massive research into patterns or correlations in large databases could replace hypothetic-deductive and model-based approaches. For instance, by relying on a massive amount of examples, translations could potentially be done without any grammatical models, and species could be identified by their genomic signature without knowing much biology.

## 5. A New Definition of Digital Humanities
### 5.1. Big Cultural Datasets as a defining characteristic of Digital Humanities

Main proposal : **(Big Data) Digital Humanities deal with Big Cultural Datasets.** Cultural Datasets are Big either because they are hard to process, open-ended, fundamentally networked or sufficiently dense to lead to data-driven approach.

**Big Cultural Datasets** are specific objects of studies, as neither Computer Science nor the Humanities are equipped to adequately deal with these large objects. **It is the very existence of this specific kind of objects that make Digital Humanities a field of its own (and not just an intersection zone).** This can be thought of as a _hard definition_ of Digital Humanities, by contrast to the softer passive definition of DH as a "simple" membrane between Computer Science and Humanities.

### 5.2. The two definitions of Digital Humanities

- **Soft Definition**: Digital Humanities constitute an interdisciplinary field at the intersection of Humanities and Digital approaches. Digital Humanities will remain a diaphragm zone.

- **Hard Definition**: Digital Humanities constitute a field of its own, studying a new kind of objects: _Big Cultural Data Sets_. Digital Humanities will be a new independent domain.

## 6. The Three Circles Representation of Digital Humanities

Let us now introduce a representation of the field of Digital Humanities as such: three concentric circles.

### 6.1. First Circle: Big Cultural Data

The first (inner) circle corresponds to research focusing on processing and interpreting these big and networked cultural data sets. For instance, each photo uploaded to Facebook is processed in series of consecutive steps, including machine learning analysis, face recognition, etc. The study of this ever expanding corpus needs new specific methods.

The particularly complex nature of Cultural Datasets makes these processing specific compare to standard Data Science methods. We will see in details the nature of the complexity in the next course which is focusing on “historic" Big Cultural Datasets (Big Data of the Past)

### 6.2. Second Circle: Digital Culture

It is important to consider that data processing and interpretation occur in a larger context of the new digital culture characterized by collective discourses, large community, ubiquitous software, and global IT actors. Understanding the relations between these entities could be considered the second object of study for Big Data Digital Humanities, what we call here, the second circle.

Consider again the millions of photos shared every hour on Facebook. Large-scale communities produce both the massive digital objects and the collective discourses about massive digital objects. They do so through the mediation of algorithms produced by one giant IT company of the web. Retroactively, collective discourses about the photos have a shaping role on the emergence and structuring of these communities. In addition, as collective discourses rapidly reach a critical mass (e.g., millions of messages or status update) they tend to become themselves massive digital objects, to be archived and studied through specific text and data mining approaches.

Understanding photo sharing implies understanding the complexity of this network of interactions (which, as a side note, is not specific to Big Data and can be traced back to any scenario which features a new technology in a mediating role – like with the printing press, which soon after its invention, had of course a major effect on discourses and communities).

- The **processing domain** (1) covers the interaction between the software and massive digital object from a technical and epistemological perspective, studying in particular how to design data-processing algorithms capable of deriving new data out of massive digital objects.This corresponds to the first circle.

- The **discursive domain** (2) covers the study of the shape of collective discourses in relation with digital cultural objects, from Facebook to scientific articles. Discourse is not limited to textual domain but also includes video productions. Specific algorithmic methods must be invented to observe in time and space the continuous evolution of such discourses.

- The **social shaping domain** (3) studies how large-scale communities shape and are shaped by the collective discourses they produce.This includes polarisation dynamics on Twitter or YouTube but also communities formations in other more specific communities (Wikipedia, gamers, developers, etc.).

- The algorithmic **mediation domain** (4) studies how software mediates discourses and organises communities. This includes the specific effects of sorting algorithms, filter bubbles, scoring systems but also platform effects in Education and Science.

- The **control domain** (5) covers the relationship of communities and global actors with massive digital objects and the software medium. The domain studies how global actors curate both big cultural datasets and software medium to process them or how symmetrically, large-scale communities create or use software infrastructure for instance in the context of open-source communities.

### 6.3. Third Circle: Digital Experiences

The final (exterior) circle lies closer to us, and has something to do with how we, as humans, interact with such data. Big Cultural Datasets, once processed and discussed, can produce experiences – like physical interfaces, websites, installations, exhibitions to name a few.

Studying how the possible experiences of this third circle lie in abstract spaces has formed a field of study of its own.

## 7. Conclusion
### 7.1. Summary

- It can be argued that (Big Data) Digital Humanities study a new kind of object : **Big Cultural Data Sets**. Neither Computer Science nor Traditional Humanities know how to deal with it.

- As a consequence, some consider that Research in Digital Humanities is a field on its own, organising a restructuring of knowledge based on new domain of investigations focusing of processing, discursive, social shaping, algorithmic mediation and control relations. In this perspective, Digital Humanities also study the experiences produced by these relations and the new interfaces mediate them. This can be considered a hard definition of Digital Humanities.  

### 7.2. In the next Chapter

_Digital Humanities deals with Big Cultural Datasets like Wikipedia or Facebook's photo archives. But do such datasets exist for the past? Beyond Big Data of the present, can we talk of a Big Data of the Past?_

## Further Reading

- Jacquesson 2010 on Google Books.
- Gold M., Debates in the Digital Humanities
- CP Snow, The Two Cultures and the Scientific Revolution
- Datafication
