---
title: 'Foundations in Digital Humanities 1.3'
subtitle: 'What are Digital Humanities'
author:
 - Frederic Kaplan

# Don't change the following lines
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyfoot[L]{-release-version-}
output: pdf_document

---

# Big Data of the Past

## Spatial and temporal horizons

In 1896, in Geneva, the two million visitors to the national exhibition could for the first time discover their city from the air. In small groups, from the gondola of a helium balloon, they could see how the city had changed considerably in recent decades. Following in the footsteps of other European capitals at the end of the 19th century, the old medieval city had now become an open, airy, cosmopolitan city, built for walking rather than defence, a city of its time. This view of the sky, absolutely unheard of at a time when air travel was still only a dream of the future, made it possible at a glance to embrace the structure and motifs of the new city. It offered a viewpoint and an understanding that no speech could have summed up. 

Let us try to imagine the experience of those visitors at the end of the 19th century, who were not accustomed to aerial views and who for many were boarding a balloon for the first time. The exhilaration of the panorama comes from a sudden transformation of the relationship between space and time, a spatiotemporal compression. From a single point, it suddenly becomes possible to glimpse in a new form the places that took hours to reach. The sudden overabundance of available information makes you dizzy. Where to look? The eye is desperately looking for global motives or on the contrary for a singular detail to make this spectacle too rich, too dense, to make it intelligible, to make it return to the order of the discourse, to be able once back down to say what we have seen. But the panorama only allows us to tell the story in a very partial way. Once down, visitors will generally have to be content to talk about the vertiginous experience as such rather than its content. 

Still at the Geneva World Fair, but on land this time, as an echo to this first vertiginous panorama, another type of show was proposed in a pavilion in the Parc de Plaisance. This was a large model of almost 30 m2, representing Geneva in 1850 and entitled "Grand Relief du Vieux Genève". Despite the large dimensions of this three-dimensional model, the old city was reconstructed with great care. Visitors looking down over the model were once again placed in a panoramic view, but this time facing the artificial reconstruction of a vanished landscape. 

The author of the model, Auguste Magnin (1841-1903), had spent almost 18 years meticulously building this model in the attic of his architect's studio. The whole thing weighed almost 670 kilos. For this project, he had first gathered extensive documentation, drawn up field surveys, traced maps and views of the town and finally drawn up final plans for each group of houses. Magnin had made initial cardboard models to assess the complexity of the task and dimension his project, and then gradually converged on a combination of processes to build the model. It was based on a wooden structure supporting an assembly of 120 caissons, followed by a model of the terrain using one-centimetre thick planks. Façades and walls were built from welded zinc sheets. Roof tiles and street paving stones were imitated by electroplating. By means of acid etching, he was able to reproduce the paving of the walls of the fortifications. The 1500 trees in the model were made of cast iron, all different. Variations in the arrangement of the branches suggested the shape of a plane tree, a poplar or a fir tree. Magnin had chosen to keep the zinc and copper in their natural colour, favouring above all the aesthetics and overall rendering of the model rather than pursuing an impossible attempt at realism. 

Using archives, land surveys and old maps, Magnin had to reconstruct the underlying structure of the Geneva of 1850, understand the architectural and urban grammar, and then choose the technical processes to recreate what finally became a simulation of the vanished city. At each stage he had made multiple choices. To increase the legibility of the recreated model, Magnin had not hesitated to work on three different scales: 1/250th for the plan, 1/200th for the elevation and 1/100th for the terrain. If Magnin had kept a constant scale, the city would have been crushed. By distorting the heights, Magnin's model gained in visual efficiency, and better reflected the details of the city, even if on principle it lost its fidelity and ceased to be an absolutely realistic model of the ancient city._

Magnin was precisely motivated to work on this long allene work by the great urbanistic upheavals that were affecting Geneva in the second half of the 19th century. Geneva was given a new structure. A new urban grammar was to cover the Old City. Magnin chose the symbolic date of 1850, as it corresponded to the first blows of the pickaxe to the fortifications of the Huguenot city, the beginning of the end of a world. For him, it was not so much a question of recording its traces as of making it visible again, in the most impressive and educational way, using the technology of his time. The panorama of old Geneva was to be as spectacular as that of the New City seen from the sky. The work of a single man who was struggling to bring the past to life in a changing world, the Magnin relief carries within it the ambiguities of the work of fine granular historical reconstruction, a question which is, as we shall see, eminently contemporary.  The Magnin relief was not a reproduction, but an informed reinvention of the past, an attempt to make the past present. 

## Planterary-scale interfaces

In less than ten years our relationship to space has changed considerably. With just a few clicks we can now from a distant view of the Earth, quite similar to the first images taken by the Apollo astronauts, zoom in and see what a region looks like as if we were a bird flying over it. Often we can also see what a building looks like from a nearby street and literally move around as if we were there. It took only a few years for the planetary urban space to become an algorithmic space, mapped, photographed, articulated to be explorable through the interfaces of our computers. The globe was not only imaged, it was "machine-machined". 

The profound consequences of these fantastic vision devices are still to be studied. But one remark is immediately obvious: time seems singularly invisible to this device.  Is it really the present that the algorithmic globe gives me to see? How old are the aerial images shown to me by the interface? Were they taken at the same time as those used to build the immersive navigation that now allows me to see the same building in profile?  I look at this image taken of a city as the crow flies, then I dive into one of these streets without knowing if this new shot was captured the same year as the aerial view. In fact, when I think about it, I know that these two ways of documenting and representing space are not synchronised. I have no idea when the images taken by the satellite or the aeroplane that allow us to see the city from above, or when the car that collects the images of the facades of the buildings passed through these streets. We go from one vision device to another, in complete continuity, as if we were living in a perpetual present utopia. 

This travesty of time seems to be a characteristic feature of the information systems that have developed in the first decade of the 21st century. The information deluge that we have been experiencing for several years now has led each actor to face up to the most pressing need: to organise the world's information, to categorise it, to articulate it to form large cartographic systems and large databases capable of bringing order to chaos. In addition to the possibility of tracing in real time the movement of people and goods, the exchange of messages, financial transactions, the development of generalised audio-visual capture systems from video surveillance to satellite imagery, has been added the opportunity for each owner of a portable computer device to document his or her own life in a way that was never possible before. Each of this captured information is potentially indexed in time and space, integrating into a four-dimensional coordinate system, but always according to a logic of stability of our modes of representation. However, nothing is less stable over time than the modes of information organisation.  

## The Information Mushroom

If we were indeed faced with "Big data from the past", could we imagine extending the most popular services on the Internet to give them back what they sorely lack: duration, long time? Could we imagine a "Google map of the past" equipped with a "slider" allowing us to see the same place 50, 100 or 1000 years earlier? Could we imagine reconstructing a "Facebook of the past", reproducing the links that united millions of people in the Middle Ages, chronicling their lives with a density equivalent to that which characterises our life stories today? Perhaps building a time machine today would mean exactly that: making the past as present as the present, integrating it into the global information system. 

One way of thinking about this perhaps impossible dream is to think of the amount of digital information we have about each era as a mushroom. If we place time vertically and the amount of information available horizontally, the information deluge of the last ten years can be visualised as a large horizontal plateau resting on a base that keeps getting smaller and smaller as we go down into the past. To build a Google map or a Facebook of the past, we need to somehow transform this mushroom into a rectangle, widen its base to make it comparable to the size of the table, somehow obtain an information density that is as important for the past as it is for the present.

A first approach consists in conducting vast digitisation projects, then systematically extracting information from these digitised collections. The Google books project has thus digitised almost 30 million books and transcribed with automatic reading software a large proportion of them, making them indexable and searchable. This database, even if it is made up of extremely disparate elements (what could be more different from one book than another) is nevertheless a very rich source of information. The major projects to digitise the press are moving in the same direction, making it possible to obtain detailed information on local and international events on a daily basis, but also stock market prices, train timetables, classified ads, etc. The digitisation of administrative data provides systematically structured information documenting births, deaths, marriages, wills, changes of ownership or cadastral changes. An extremely large number of private archives have been added to this already very rich collection of information with photographs and letters. 

The archival and documentary logic put in place at the beginning of the 19th century in France or Italy, for example, still has much in common with that which is at work today. For this reason, there is no doubt that over the last two hundred years, for example, by increasing the information extracted from press articles and administrative records, a relatively accurate picture of a country's society and its day-to-day development can be reconstructed. Obviously, the further back we go in the past, the more the number of documents is reduced and, above all, the more the logic of representation becomes alien. The documentary structures put in place during the Renaissance, in line with the spread of printing, require specific work to be interpreted according to the logics of contemporary information systems. The documentary situation in the Middle Ages and earlier periods obviously poses many other challenges. 

To compensate for the lack of archival information or to complete the spaces not covered by the archives, we can adopt a complementary strategy that is not foreign to the historian by reconstructing the missing data by extrapolation and generalisation. If a historian finds the logbook of a 16th century ship's captain documenting precisely a voyage between Venice and Corfu, he will not only be able to draw conclusions about that particular voyage but will, under certain conditions, be able to use this document to deduce information about the modes of navigation and maritime life of that period. In the same way, we can use architectural information from a Venetian palazzo in Gothic style which is still very well preserved to make hypotheses about the structure and style of a building of the same period and with similar functions but which is now completely destroyed. It is always a question of going beyond the information contained in a particular document, extracting structures, grammars and using them to build motivated hypotheses that allow us to fill in the blanks left between the archives. In computer science, these techniques correspond to the large family of simulation methods that have been studied for more than 50 years.  The problem of discovering structures in noisy data, of generalisation from examples, of extrapolation according to certain working hypotheses is the basis of a science which has developed in parallel with the historical sciences.  The "Big data of the past" may herald a fertile and new interface between these fields and in any case invite reflection on the singular epistemological status of these "reconstructed pasts". 

Simulation cannot be understood as a way of simply compensating for the lack of historical data, used only when archival data is lacking. In fact there is never enough data. No cadastral plan, no photo, no laser survey, could allow me to reconstruct precisely the structure of a single _calle_ in Venice. Even in situations of "hyper-documentation", at some point the data has to be extended according to certain hypotheses. Simulations and data always go hand in hand. Only the resolution and the uncertainty change. 


## Summary



## Further Reading



