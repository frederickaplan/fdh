---
title: 'Foundations in Digital Humanities 3.1'
subtitle: 'Knowledge Modelling'
author:
 - Frederic Kaplan

# Don't change the following lines
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyfoot[L]{-release-version-}
output: pdf_document


---

# Knowledge Modelling

(This chapter may be put at the end of the the pipeline, for coherence and replace by a chapter on formal systems and rules. The new chapter rules could introduce the subject with Game as formal system, illustrating the idea with Minecraft for instance)

(Maybe call it Symbolic Modelling)

## Situation so far

> Definition : Information is a difference that makes a difference

Typically the difference in a shape of a curve (cf Leyton)

Symbolsl : 

Glyphs : 

- Sets 
  - 3D Volume in documents (book chapter)
  - 3D volume on earth
  - 4D volume
- Points
  - 2D : Points on images
  - 3D : Points in 3D (linked with photogrammetric anchors)
  - Painting in shape space
  - Words in large word space and embeddings 
  - Discourse in discourse space
- Vector
  - Relation between words

## Concepts

The beauty of Knowledge modelling. Tables. Databases. Semantic web, Ontologies, URI, RDF, CIDOC-CRM, How to code event, places and influence. Metaknowledge. The Hypergraph



Detection of causal chains. Inference of Graphs



## Practice

Graph writing. Presentation of some interesting ontologies: SKOS, VIAF, Geonames, TGN, W3C Time Ontology. SPARQL and SPARQL endpoint. Exercice on SPARQL endpoints: DBPedia [[1\]](http://dbpedia.org/sparql), Talk of Europe [[2\]](http://linkedpolitics.ops.few.vu.nl/yasgui/index.html), Pers√©e [[3\]](http://data.persee.fr/explorer/), Le Temps ARchive [[4\]](http://iccluster052.iccluster.epfl.ch:8899/sparql), available on [this Github repository](https://github.com/dhlab-epfl/fdh-tutorials). (

LOAD model (Andrea Spitz)

HDT http://www.rdfhdt.org/what-is-hdt/

"Currently RDF data is stored and sent in very verbose textual serialization formats that waste a lot of bandwidth and are expensive to parse and index. If RDF is meant to be machine understandable, why not use an appropriate format for that?

HDT (Header, Dictionary, Triples) is a **compact data structure** and **binary serialization format** for RDF that keeps big datasets **compressed** to save space while maintaining **search** and **browse** operations without prior decompression. This makes it an ideal format for storing and sharing RDF datasets on the Web."

JustGUI

Datafirst. 

Converting a CSV in RDF

Explorting RDF

Example Druid : Data Stories as Notebooks

## Meta-modelling

## Modelling ignorance

## Rules-based systems and inferences

(This could be the subject of a separated chapter)

- Expert systems
- Constraint based systems
- Cognitive computing



## Question and Answers 



## Further Reading

- Eco Umberto, Vertige de la liste

- Marhias Girel, Science et territoires de l'ignorance

- Stephen Wolfram, An elementary introduction to the Wolfram Language

- Schaeffer, Tresch, Gagliardi, Aesthetics of Universal Language

- Levy, la sphere semantique

- Wolfram, The Wolfram Language

- Latour, B., 2005. *[Reassembling the Social: An Introduction to Actor-Network-Theory](https://en.wikipedia.org/wiki/Bruno_Latour#Reassembling_the_Social)*. Oxford: Oxford UP

- Akrich, M., M. Callon, B. Latour, 2006, Sociologie de la traduction. Textes fondateurs, Paris, Les Presses des Mines

  

  